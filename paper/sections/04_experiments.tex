% -----------------------------------------------------------------------------
\section{Experiments}
% -----------------------------------------------------------------------------
We benchmark the \textsc{LCT} layer on two standard settings:
\begin{enumerate}
  \item \textbf{Language Modelling}: WikiText‐103 using the NanoGPT backbone.
  \item \textbf{Image Classification}: ImageNet‐32 with a ViT‐Tiny architecture.
\end{enumerate}

Training uses AdamW with identical hyper‐parameters across baselines.  Details are in Appendix~A.