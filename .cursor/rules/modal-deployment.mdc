---
description: 
globs: **.py,*.py
alwaysApply: false
---
# Modal Deployment Guidelines

## Introduction / Problem

The codebase is developed locally on macOS but needs to run on Modal's Linux H100 cluster for training. This creates a development/deployment split that needs careful management, particularly around PyTorch dependencies and CUDA compatibility.

## Development Environment

Local development uses:
- macOS with CPU-only PyTorch
- Local pytest for unit tests
- VSCode for development
- `uv` for dependency management

This explains the linter errors about unresolved torch imports - they're expected on macOS since we're using a minimal local environment.

## Modal Deployment

The Modal deployment is configured in [modal_app.py](mdc:modal_app.py) and handles:

1. Container setup with CUDA-enabled PyTorch
2. H100 GPU allocation
3. Data volume mounting
4. Training orchestration

### Key Components

```python
# Example Modal stub configuration
@stub.function(gpu="H100", memory=32768)
def train_nanogpt():
    import torch
    assert torch.cuda.is_available()
    assert torch.cuda.get_device_name() == "NVIDIA H100 PCIe"
    # ... training code ...
```

## Implementation Steps

1. Local Development:
   - Use `uv` for dependency management
   - Run CPU-only tests with `pytest`
   - Implement features in `torchlayers/`
   - Use type hints and docstrings extensively

2. Modal Deployment:
   - Update `modal_app.py` for new features
   - Test with small models first
   - Scale up gradually to full H100 utilization

3. Continuous Integration:
   - CPU tests run locally and in CI
   - GPU tests run on Modal during pre-merge checks

## Common Pitfalls

| Pitfall | Fix |
|---------|-----|
| PyTorch import errors locally | Ignore in linter, focus on type checking |
| CUDA-specific code failing locally | Guard with `if torch.cuda.is_available()` |
| Memory issues on H100 | Use `torch.cuda.empty_cache()` and gradient checkpointing |

## Real-World Examples

* [modal_app.py](mdc:modal_app.py) - Main Modal deployment configuration
* [train_gpt.py](mdc:train_gpt.py) - Training script with H100 optimizations

## Automation Hints

Add to your Justfile:

```makefile
deploy:
    modal deploy modal_app.py

run:
    modal run modal_app.py

monitor:
    modal logs modal_app.py
```

## See Also

* Modal docs: <https://modal.com/docs/guide/gpu>
* PyTorch CUDA: <https://pytorch.org/docs/stable/cuda.html>
